#pragma once

#include <immintrin.h>

#include <cassert>  // needed for xsimd
#include "../Tensor.h"
#include "base.h"
#include "elementwise.h"
#include "xsimd/xsimd.hpp"
namespace sail {

/** begin block
 * name = [Add, Sub, Multiply, Divide]
 * baseOp = [+, -, *, /]
 * avxOp = [add, sub, mul, div]
 */

class $name$TTKernel : public Kernel {
   public:
    void execute(Tensor& t1, Tensor& t2, Tensor& out_tensor) {
        launch_arithmetic(t1.dtype, [&](auto pt) {
            // std::cout << decltype(pt)::type << std::endl;

            using DtypeType = decltype(pt);

            using T = typename DtypeType::type;
            using avx_name = typename DtypeType::avx_type;

            const auto avx_data = DtypeType::avx_data;

            static const auto fcn = avx_data.$avxOp$;
            static const auto load = avx_data.avx_load;
            static const auto loadu = avx_data.avx_loadu;

            static const auto store = avx_data.avx_store;
            static const auto storeu = avx_data.avx_storeu;

            using avx_type = xsimd::simd_type<T>;
            // std::size_t inc = avx_type::size;
            // std::size_t size = res.size();
            // size for which the vectorization is possible
            // std::size_t vec_size = size - size % inc;

            struct Impl {
                inline void call_base(T x1, T x2, T& out) {
                    out = x1 $baseOp$ x2;
                }
                inline avx_name avx_call(avx_name a, avx_name b) {
                    return fcn(a, b);
                }

                inline void call_avx_aligned(T* x1, T* x2, T* out) {
                    // avx_name a = load(x1);
                    // avx_name b = load(x2);
                    // avx_name res = avx_call(a, b);
                    // store(out, res);
                    avx_type a = xsimd::load_aligned(x1);
                    avx_type b = xsimd::load_aligned(x2);
                    auto c = a $baseOp$ b;
                    // std::cout << "this" << std::endl;
                    xsimd::store_unaligned(out, c);
                }

                inline void call_avx_non_aligned(T* x1, T* x2, T* out) {
                    avx_name a = loadu(x1);
                    avx_name b = loadu(x2);
                    avx_name res = avx_call(a, b);
                    storeu(out, res);
                }
            };

            BinaryElementwise<T, T, T>(Impl{}, t1, t2, out_tensor);
        });
    }
};

/** end block **/

/** begin block
 * name = [Add, Sub, Multiply, Divide]
 * baseOp = [+, -, *, /]
 * avxOp = [add, sub, mul, div]
 */

class $name$TSKernel : public Kernel {
   public:
    void execute(const Tensor& t1, const Tensor& t2, Tensor& out_tensor) {
        launch_arithmetic(t1.dtype, [&](auto pt) {
            // std::cout << decltype(pt)::type << std::endl;
            using T = typename decltype(pt)::type;
            using avx_name = typename decltype(pt)::avx_type;

            static const auto fcn = decltype(pt)::avx_data.$avxOp$;
            static const auto load = decltype(pt)::avx_data.avx_load;
            static const auto loadu = decltype(pt)::avx_data.avx_loadu;

            static const auto store = decltype(pt)::avx_data.avx_store;
            static const auto storeu = decltype(pt)::avx_data.avx_storeu;

            struct Impl {
                inline void call_base(T x1, T x2, T& out) {
                    out = x1 $baseOp$ x2;
                }
                inline avx_name avx_call(avx_name a, avx_name b) {
                    return fcn(a, b);
                }

                inline void call_avx_aligned(T* x1, T* x2, T* out) {
                    avx_name a = load(x1);
                    avx_name b = load(x2);
                    avx_name res = avx_call(a, b);
                    store(out, res);
                }

                inline void call_avx_non_aligned(T* x1, T* x2, T* out) {
                    avx_name a = loadu(x1);
                    avx_name b = loadu(x2);
                    avx_name res = avx_call(a, b);
                    storeu(out, res);
                }
            };

            BinaryElementwiseScalar<T, T, T>(Impl{}, t1, t2, out_tensor);
        });
    }
};

/** end block **/

}  // namespace sail
