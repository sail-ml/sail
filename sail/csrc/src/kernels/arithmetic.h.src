#pragma once

#include <immintrin.h>

#include "../Tensor.h"
#include "base.h"

namespace sail {


/** begin block
 * name = [Add, Sub, Multiply, Divide]
 * baseOp = [+, -, *, /]
 * avxOp = [add, sub, mul, div]
 */

    
class $name$TTKernel : public Kernel {
   public:
    void execute(Tensor& t1, Tensor& t2, Tensor& out_tensor) {
        launch_arithmetic(t1.dtype, [&](auto pt) {

            // std::cout << decltype(pt)::type << std::endl;
            using T = typename decltype(pt)::type;
            using avx_name = typename decltype(pt)::avx_type;

            static const auto fcn = decltype(pt)::avx_data.$avxOp$;
            static const auto load = decltype(pt)::avx_data.avx_load;
            static const auto loadu = decltype(pt)::avx_data.avx_loadu;

            static const auto store = decltype(pt)::avx_data.avx_store;
            static const auto storeu = decltype(pt)::avx_data.avx_storeu;
            

            struct Impl {

                inline void call_base(T x1, T x2, T& out) {
                    out = x1 $baseOp$ x2;
                }
                inline avx_name avx_call(avx_name a, avx_name b) {
                    return fcn(a, b);
                }

                inline void call_avx_aligned(T* x1, T* x2, T* out) {
                    avx_name a = load(x1);
                    avx_name b = load(x2);
                    avx_name res = avx_call(a, b);
                    store(out, res);
                }
 
                inline void call_avx_non_aligned(T* x1, T* x2, T* out) {
                    avx_name a = loadu(x1);
                    avx_name b = loadu(x2);
                    avx_name res = avx_call(a, b);
                    storeu(out, res);
                }
            };

            ElemetwiseAVX<T, Impl, avx_name>(Impl{}, t1, t2, out_tensor);
            
        });
    }
};


/** end block **/

/** begin block
 * name = [Add, Sub, Multiply, Divide]
 * baseOp = [+, -, *, /]
 * avxOp = [add, sub, mul, div]
 */

class $name$TSKernel : public Kernel {
   public:
    void execute(const Tensor& t1, const Tensor& t2, Tensor& out_tensor) {
        launch_arithmetic(t1.dtype, [&](auto pt) {
            // std::cout << decltype(pt)::type << std::endl;
            using T = typename decltype(pt)::type;
            using avx_name = typename decltype(pt)::avx_type;

            static const auto fcn = decltype(pt)::avx_data.$avxOp$;
            static const auto load = decltype(pt)::avx_data.avx_load;
            static const auto loadu = decltype(pt)::avx_data.avx_loadu;

            static const auto store = decltype(pt)::avx_data.avx_store;
            static const auto storeu = decltype(pt)::avx_data.avx_storeu;

            struct Impl {
                inline void call_base(T x1, T x2, T& out) {
                    out = x1 $baseOp$ x2;
                }
                inline avx_name avx_call(avx_name a, avx_name b) {
                    return fcn(a, b);
                }

                inline void call_avx_aligned(T* x1, T* x2, T* out) {
                    avx_name a = load(x1);
                    avx_name b = load(x2);
                    avx_name res = avx_call(a, b);
                    store(out, res);
                }
 
                inline void call_avx_non_aligned(T* x1, T* x2, T* out) {
                    avx_name a = loadu(x1);
                    avx_name b = loadu(x2);
                    avx_name res = avx_call(a, b);
                    storeu(out, res);
                }
            };

            ElemetwiseScalarAVX<T, Impl, avx_name>(Impl{}, t1, t2, out_tensor);
        });
    }
};

/** end block **/

}  // namespace sail
