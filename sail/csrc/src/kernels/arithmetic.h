/*
################################################################################
#                  THIS CODE IS AUTOGENERATED FROM A TEMPLATE                  #
#                 TO MAKE CHANGES, EDIT THE ORIGINAL .src FILE                 #
################################################################################
*/

#pragma once

#include <immintrin.h>

#include "../Tensor.h"
#include "base.h"



namespace sail {

/** begin block
 * name = [Add, Sub, Multiply, Divide]
 * baseOp = [+, -, *, /]
 * avxOp = [add, sub, mul, div]
 */


class AddTTKernel : public Kernel {
    public:
        void execute(const Tensor& t1, const Tensor& t2, Tensor& out_tensor) {
            launch_arithmetic(t1.storage.dtype, [&](auto pt) {
                // std::cout << decltype(pt)::type << std::endl;
                using T = typename decltype(pt)::type;    
                using avx_name = typename decltype(pt)::avx_type;    
                struct Impl {                                                                                        
                    inline void call_base(T x1, T x2, T& out) {     
                        out = x1 + x2;  
                    }       
                    inline avx_name avx_call(avx_name a, avx_name b) {
                        return _mm256_add_pd(a,b);
                    }                                                                                 
                    inline void call_avx_aligned(avx_name a, avx_name b, T* out) {
                        avx_name res = avx_call(a, b);
                        _mm256_store_pd(out, res);
                    }                                                                              
                    inline void call_avx_non_aligned(avx_name a, avx_name b, T* out) {
                        avx_name res = avx_call(a, b);
                        _mm256_storeu_pd(out, res);
                    }                                                                              
                };   

                ElemetwiseAVX<T, Impl, avx_name>(Impl{}, t1, t2, out_tensor);
            });
        }
};



class SubTTKernel : public Kernel {
    public:
        void execute(const Tensor& t1, const Tensor& t2, Tensor& out_tensor) {
            launch_arithmetic(t1.storage.dtype, [&](auto pt) {
                // std::cout << decltype(pt)::type << std::endl;
                using T = typename decltype(pt)::type;    
                using avx_name = typename decltype(pt)::avx_type;    
                struct Impl {                                                                                        
                    inline void call_base(T x1, T x2, T& out) {     
                        out = x1 - x2;  
                    }       
                    inline avx_name avx_call(avx_name a, avx_name b) {
                        return _mm256_sub_pd(a,b);
                    }                                                                                 
                    inline void call_avx_aligned(avx_name a, avx_name b, T* out) {
                        avx_name res = avx_call(a, b);
                        _mm256_store_pd(out, res);
                    }                                                                              
                    inline void call_avx_non_aligned(avx_name a, avx_name b, T* out) {
                        avx_name res = avx_call(a, b);
                        _mm256_storeu_pd(out, res);
                    }                                                                              
                };   

                ElemetwiseAVX<T, Impl, avx_name>(Impl{}, t1, t2, out_tensor);
            });
        }
};



class MultiplyTTKernel : public Kernel {
    public:
        void execute(const Tensor& t1, const Tensor& t2, Tensor& out_tensor) {
            launch_arithmetic(t1.storage.dtype, [&](auto pt) {
                // std::cout << decltype(pt)::type << std::endl;
                using T = typename decltype(pt)::type;    
                using avx_name = typename decltype(pt)::avx_type;    
                struct Impl {                                                                                        
                    inline void call_base(T x1, T x2, T& out) {     
                        out = x1 * x2;  
                    }       
                    inline avx_name avx_call(avx_name a, avx_name b) {
                        return _mm256_mul_pd(a,b);
                    }                                                                                 
                    inline void call_avx_aligned(avx_name a, avx_name b, T* out) {
                        avx_name res = avx_call(a, b);
                        _mm256_store_pd(out, res);
                    }                                                                              
                    inline void call_avx_non_aligned(avx_name a, avx_name b, T* out) {
                        avx_name res = avx_call(a, b);
                        _mm256_storeu_pd(out, res);
                    }                                                                              
                };   

                ElemetwiseAVX<T, Impl, avx_name>(Impl{}, t1, t2, out_tensor);
            });
        }
};



class DivideTTKernel : public Kernel {
    public:
        void execute(const Tensor& t1, const Tensor& t2, Tensor& out_tensor) {
            launch_arithmetic(t1.storage.dtype, [&](auto pt) {
                // std::cout << decltype(pt)::type << std::endl;
                using T = typename decltype(pt)::type;    
                using avx_name = typename decltype(pt)::avx_type;    
                struct Impl {                                                                                        
                    inline void call_base(T x1, T x2, T& out) {     
                        out = x1 / x2;  
                    }       
                    inline avx_name avx_call(avx_name a, avx_name b) {
                        return _mm256_div_pd(a,b);
                    }                                                                                 
                    inline void call_avx_aligned(avx_name a, avx_name b, T* out) {
                        avx_name res = avx_call(a, b);
                        _mm256_store_pd(out, res);
                    }                                                                              
                    inline void call_avx_non_aligned(avx_name a, avx_name b, T* out) {
                        avx_name res = avx_call(a, b);
                        _mm256_storeu_pd(out, res);
                    }                                                                              
                };   

                ElemetwiseAVX<T, Impl, avx_name>(Impl{}, t1, t2, out_tensor);
            });
        }
};

/** end block **/

/** begin block
 * name = [Add, Sub, Multiply, Divide]
 * baseOp = [+, -, *, /]
 * avxOp = [add, sub, mul, div]
 */


class AddTSKernel : public Kernel {
    public:
        void execute(const Tensor& t1, const Tensor& t2, Tensor& out_tensor) {
            launch_arithmetic(t1.storage.dtype, [&](auto pt) {
                // std::cout << decltype(pt)::type << std::endl;
                using T = typename decltype(pt)::type;    
                using avx_name = typename decltype(pt)::avx_type;    
                struct Impl {                                                                                        
                    inline void call_base(T x1, T x2, T& out) {     
                        out = x1 + x2;  
                    }       
                    inline avx_name avx_call(avx_name a, avx_name b) {
                        return _mm256_add_pd(a,b);
                    }                                                                                 
                    inline void call_avx_aligned(avx_name a, avx_name b, T* out) {
                        avx_name res = avx_call(a, b);
                        _mm256_store_pd(out, res);
                    }                                                                              
                    inline void call_avx_non_aligned(avx_name a, avx_name b, T* out) {
                        avx_name res = avx_call(a, b);
                        _mm256_storeu_pd(out, res);
                    }                                                                                
                };   

                ElemetwiseScalarAVX<T, Impl, avx_name>(Impl{}, t1, t2, out_tensor);
            });
        }
};



class SubTSKernel : public Kernel {
    public:
        void execute(const Tensor& t1, const Tensor& t2, Tensor& out_tensor) {
            launch_arithmetic(t1.storage.dtype, [&](auto pt) {
                // std::cout << decltype(pt)::type << std::endl;
                using T = typename decltype(pt)::type;    
                using avx_name = typename decltype(pt)::avx_type;    
                struct Impl {                                                                                        
                    inline void call_base(T x1, T x2, T& out) {     
                        out = x1 - x2;  
                    }       
                    inline avx_name avx_call(avx_name a, avx_name b) {
                        return _mm256_sub_pd(a,b);
                    }                                                                                 
                    inline void call_avx_aligned(avx_name a, avx_name b, T* out) {
                        avx_name res = avx_call(a, b);
                        _mm256_store_pd(out, res);
                    }                                                                              
                    inline void call_avx_non_aligned(avx_name a, avx_name b, T* out) {
                        avx_name res = avx_call(a, b);
                        _mm256_storeu_pd(out, res);
                    }                                                                                
                };   

                ElemetwiseScalarAVX<T, Impl, avx_name>(Impl{}, t1, t2, out_tensor);
            });
        }
};



class MultiplyTSKernel : public Kernel {
    public:
        void execute(const Tensor& t1, const Tensor& t2, Tensor& out_tensor) {
            launch_arithmetic(t1.storage.dtype, [&](auto pt) {
                // std::cout << decltype(pt)::type << std::endl;
                using T = typename decltype(pt)::type;    
                using avx_name = typename decltype(pt)::avx_type;    
                struct Impl {                                                                                        
                    inline void call_base(T x1, T x2, T& out) {     
                        out = x1 * x2;  
                    }       
                    inline avx_name avx_call(avx_name a, avx_name b) {
                        return _mm256_mul_pd(a,b);
                    }                                                                                 
                    inline void call_avx_aligned(avx_name a, avx_name b, T* out) {
                        avx_name res = avx_call(a, b);
                        _mm256_store_pd(out, res);
                    }                                                                              
                    inline void call_avx_non_aligned(avx_name a, avx_name b, T* out) {
                        avx_name res = avx_call(a, b);
                        _mm256_storeu_pd(out, res);
                    }                                                                                
                };   

                ElemetwiseScalarAVX<T, Impl, avx_name>(Impl{}, t1, t2, out_tensor);
            });
        }
};



class DivideTSKernel : public Kernel {
    public:
        void execute(const Tensor& t1, const Tensor& t2, Tensor& out_tensor) {
            launch_arithmetic(t1.storage.dtype, [&](auto pt) {
                // std::cout << decltype(pt)::type << std::endl;
                using T = typename decltype(pt)::type;    
                using avx_name = typename decltype(pt)::avx_type;    
                struct Impl {                                                                                        
                    inline void call_base(T x1, T x2, T& out) {     
                        out = x1 / x2;  
                    }       
                    inline avx_name avx_call(avx_name a, avx_name b) {
                        return _mm256_div_pd(a,b);
                    }                                                                                 
                    inline void call_avx_aligned(avx_name a, avx_name b, T* out) {
                        avx_name res = avx_call(a, b);
                        _mm256_store_pd(out, res);
                    }                                                                              
                    inline void call_avx_non_aligned(avx_name a, avx_name b, T* out) {
                        avx_name res = avx_call(a, b);
                        _mm256_storeu_pd(out, res);
                    }                                                                                
                };   

                ElemetwiseScalarAVX<T, Impl, avx_name>(Impl{}, t1, t2, out_tensor);
            });
        }
};

/** end block **/

} // namespace end

