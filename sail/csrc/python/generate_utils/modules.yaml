
Linear:
  init:
    signature: Linear(int in_features, int out_features, bool use_bias=true)
  properties:
    weights: 
      type: Tensor
      write: True 
    biases:
      type: Tensor
      write: True 
  forward:
    signature: (Tensor x1)

Conv2D:
  init:
    signature: Conv2D(int input_channels, int output_channels, sequence kernel_size, sequence strides, bool use_bias=true)
    custom: |
      int input_channels;
      int output_channels;
      int use_bias = 1;
      PyObject * kernel_size;
      PyObject * strides;
      static char* kwlist[] = { "input_channels", "output_channels", "kernel_size", "strides", "use_bias", NULL };

      if (!PyArg_ParseTupleAndKeywords(args, kwargs, "iiOO|p", kwlist, &input_channels, &output_channels, &kernel_size, &strides, &use_bias)) {
          PyErr_SetString(PyExc_TypeError, "incorrect arguments");
          return -1;
      }

      if (PyLong_Check(kernel_size) && PyLong_Check(strides)) {
          self->module = (Module *)(new sail::modules::Conv2D(input_channels, output_channels, PyLong_AsLong(kernel_size), PyLong_AsLong(strides), "same", (bool)use_bias));
      } else {
        std::vector<long> kernel, stride;
        if (PySequence_Check(kernel_size)) {
          int size = PySequence_Size(kernel_size);
          if (size == 1) {
            long val = PyLong_AsLong(PySequence_GetItem(kernel_size, 0));
            kernel.push_back(val);
            kernel.push_back(val);
          } else {
            long val = PyLong_AsLong(PySequence_GetItem(kernel_size, 0));
            kernel.push_back(val);
            val = PyLong_AsLong(PySequence_GetItem(kernel_size, 1));
            kernel.push_back(val);
          }
        } else {
            long val = PyLong_AsLong(kernel_size);
            kernel.push_back(val);
            kernel.push_back(val);
        }
        if (PySequence_Check(strides)) {
          int size = PySequence_Size(strides);
          if (size == 1) {
            long val = PyLong_AsLong(PySequence_GetItem(strides, 0));
            stride.push_back(val);
            stride.push_back(val);
          } else {
            long val = PyLong_AsLong(PySequence_GetItem(strides, 0));
            stride.push_back(val);
            val = PyLong_AsLong(PySequence_GetItem(strides, 1));
            stride.push_back(val);
          }
        } else {
            long val = PyLong_AsLong(strides);
            stride.push_back(val);
            stride.push_back(val);
        }
          self->module = (Module *)(new sail::modules::Conv2D(input_channels, output_channels, kernel, stride, "same", (bool)use_bias));
      }
      return 0;
  properties:
    weights: 
      type: Tensor
      write: True 
    biases:
      type: Tensor
      write: True 
  forward:
    signature: (Tensor x1)

MaxPool2D:
  init:
    custom: |
      PythonArgParser<3> parser = PythonArgParser<3>(
        {
            "MaxPool2D(int kernel_size, int strides = None, string padding_mode = \"valid\")",
            "MaxPool2D(IntList kernel_size, IntList strides = None, string padding_mode = \"valid\")",
        },
      args, kwargs);

      parser.parse();

      if (parser.at(0)) {
        if (parser.isNone(1)) {
          self->module = (Module *)(new sail::modules::MaxPool2D(parser.integer(0), parser.string(2)));
        } else {
          self->module = (Module *)(new sail::modules::MaxPool2D(parser.integer(0), parser.integer(1), parser.string(2)));
        }
      } else if (parser.at(1)) {
        if (parser.isNone(1)) {
          self->module = (Module *)(new sail::modules::MaxPool2D(parser.int_list(0), parser.string(2)));
        } else {
          self->module = (Module *)(new sail::modules::MaxPool2D(parser.int_list(0), parser.int_list(1), parser.string(2)));
        }
      }

      return 0;
  forward:
    signature: (Tensor x1)

Sigmoid:
  init:
    signature: ()
  forward:
    signature: (Tensor x1)
ReLU:
  init:
    signature: ()
  forward:
    signature: (Tensor x1)
Softmax:
  init:
    signature: (int axis=1)
  forward:
    signature: (Tensor x1)